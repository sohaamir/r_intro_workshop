{
  "hash": "2fc43058f748823b078b80639a38949b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Basic data management and analysis using R\"\nsubtitle: \"Analysing and plotting behavioural choice data\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\nNow that you have a basic understanding how how `R` works, and what it is used for, let's put our newly learned skills to practical use.\nIn this section we will directly work with some simulated choice data from a behavioural experiment.\n\nWhen working with data in our studies, we can consider `R` to be the central software for data management, analysis and plotting.\nIt is quite robust for this purpose, in that it also reads in data of many different types and from many different sources [^1]:\n\n[^1]: Kabacoff, R. I. (2022). R in action: data analysis and graphics with R and Tidyverse. Simon and Schuster. \n\n<div style=\"height: 5px;\"></div>\n\n![](/images/01.R_basics/data_management.png){fig-align=\"center\" width=\"60%\"}\n\n## Working with behavioural data in R\n\nWe will now work with an example dataset where participants were tasked with completing a behavioural task. \nSpecifically, they were asked to complete a **probabilistic reversal learning (PRL) task**, a common paradigm used to assess cognitive flexibility and reward-based learning. \n\nThe task consists of three main phases:\n\n1. **Choice Presentation:** Two stimuli (a blue snowflake-like pattern and a yellow spiral pattern) are presented to the participant.\n2. **Action Selection:** The participant must select one of the stimuli (shown by the red frame indicating a selection of the blue pattern).\n3. **Outcome:** A monetary reward (20 cent coin) is shown as feedback.\n\n<div style=\"height: 20px;\"></div>\n\n![](/images/01.R_basics/reversal_task.png){fig-align=\"center\" width=\"60%\"}\n\nIn the PRL task, one stimulus is typically associated with a higher probability of reward (e.g., 80% chance of winning money), and a lower probability for a loss (e.g., 20% chance of losing money).\nAfter participants learn these associations, the contingencies are reversed, requiring the participants to adapt their choices.\n\nThe participants are given instructions that:\n\n1. One option is better than the other.\n2. This will switch at various points.\n3. You should make choices to maximise your points.\n\n**Importantly, the participants are not made aware of when and how many reversals take place.** \n\nWe have example data for 10 subjects within the `data` subdirectory. Each one has an associated `raw_data_subXX.txt` file:\n\n```\n_data/\n└── RL_raw_data/\n   ├── sub01/\n   │   └── raw_data_sub01.txt\n   ├── sub02/\n       └── raw_data_sub02.txt\n   ├── ...\n   └── sub10/\n       └── raw_data_sub10.txt\n```\n\nWe need to firstly install and load the required packages:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(patchwork)\n```\n:::\n\n\nAnd now let's load the data into `R`. We can read the data using the `read.table` function, specifying in the arguments that there is a header, and that the data columns are separated by a comma. We can then check the data by loading the first few lines using the `head()` function.\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\ndata_dir = ('../_data/RL_raw_data/sub01/raw_data_sub01.txt')\ndata = read.table(data_dir, header = T, sep = \",\")\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  subjID trialID choice outcome correct\n1      1       1      1       1       1\n2      1       2      1       1       1\n3      1       3      1       1       1\n4      1       4     NA       1       1\n5      1       5      1      -1       1\n6      1       6      2      -1       1\n```\n\n\n:::\n:::\n\n\n::: {.callout-note title=\"File separators\"}\nTwo common file types are CSV (Comma-Separated Values) files which use commas to separate values, and TSV (Tab-Separated Values) files which use tabs. \n:::\n\nThe data columns represent the following:\n\n- `subjID` - the subject ID\n- `trialID` - the trial ID (80 trials per subject)\n- `choice` - which image the subject selected (blue or yellow)\n- `outcome` - whether the subject was rewarded (1) or was given a loss (-1)\n- `correct` - whether the choice made was the 'correct' one (i.e., the image with the 80% reward contingency on that trial)\n\nYou may have noticed that there are some `NA` values contained in the data, namely within the `choice` column. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(complete.cases(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 78\n```\n\n\n:::\n:::\n\n\nThis will be in trials where the participant did not respond in time (as there is a fixed time limit to respond). \n**We would like to remove these trials from the data.**\n\nWe can do this by subsetting the data to only include cases where there are no NA values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata = data[complete.cases(data),]\ndim(data[complete.cases(data),])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 78  5\n```\n\n\n:::\n:::\n\n\nSo if we examine the data now, there are no `NA` values.\n\n::: {.cell}\n\n```{.r .cell-code}\nany(is.na(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n::: {.callout-tips title=\"Many paths\"}\nThere are often many ways of doing the same act in `R`; this is just one example!\n:::\n\n::: {.callout-note title=\"Exercise 3\"}\n**1. Write a for loop which reads in each participant's raw data (from `_data/RL_raw_data/`) and reshapes it in the 'long format' by each subject.**\n\nTIP: Use the `sprintf` function to get the file paths of all subject data. Type `?sprintf` for more information.\n\n<details>\n<summary>Click to see the solution</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in all the data\nns = 10\ndata_dir = '../_data/RL_raw_data'\n\nrawdata = c()\nfor (s in 1:ns) {\n    sub_file = file.path(data_dir, sprintf('sub%02i/raw_data_sub%02i.txt',s,s))\n    sub_data = read.table(sub_file, header = T, sep = \",\")\n    rawdata = rbind(rawdata, sub_data)\n}\nrawdata = rawdata[complete.cases(rawdata),]\n\nhead(rawdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  subjID trialID choice outcome correct\n1      1       1      1       1       1\n2      1       2      1       1       1\n3      1       3      1       1       1\n5      1       5      1      -1       1\n6      1       6      2      -1       1\n7      1       7      1       1       1\n```\n\n\n:::\n:::\n\n\n</details>\n\n**2. Create a new column called `accuracy` in the `rawdata` data frame, where each row indicates whether the `choice` was correct (1.0) or incorrect (0.0).**\n\nTIP: Recall that for each trial, each `choice` can either be 1 or 2, and whether this is accurate or not is based upon the value of `correct` for that trial.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to see the solution\"}\nrawdata$accuracy = (rawdata$choice == rawdata$correct) * 1.0\n```\n:::\n\n\n**3. Calculate the mean `accuracy` for each subject and print out the overall `accuracy` across all subjects.**\n\n<details>\n<summary>Click to see the solution</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc_mean = aggregate(rawdata$accuracy, by = list(rawdata$subjID), mean)[,2]\ngroup_mean = mean(acc_mean)\n\ngroup_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7348277\n```\n\n\n:::\n:::\n\n\n</details>\n\nComplete solutions are also located within the `R_basics.R` script.\n:::\n\n::: {.callout-tip title=\"`Using sprintf`\"}\n`sprintf` is an important function used for formatting strings. It allows you to embed variables into a string with specific formatting options. For example in our use above:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsprintf('sub%02i/raw_data_sub%02i.txt', s, s)\n```\n:::\n\n\n- `%02i` specifies that the integer should be displayed with at least 2 digits, padding with leading zeros if necessary.\n- The two `s` values are passed to `sprintf` and replace the `%02i` placeholders in the string. The first `s` replaces the first `%02i`, and the second `s` replaces the second `%02i`.\n\nIf we use `%02i`:\n\n- For `s = 1`: outputs `sub01/raw_data_sub01.txt`\n- For `s = 2`: outputs `sub02/raw_data_sub02.txt`\n- For `s = 10`: outputs `sub10/raw_data_sub10.txt`\n\nIf we use `%03i`:\n\n- For `s = 1`: outputs `sub001/raw_data_sub001.txt`\n- For `s = 2`: outputs `sub002/raw_data_sub002.txt`\n- For `s = 10`: outputs `sub010/raw_data_sub010.txt`\n:::\n\n## Basic statistics: t-test, correlation and linear regression\n\nNow that we have the accuracy for each of the 10 participants, we would like to see if their accuracies are above chance level (0.5).\nChance is 0.5 because if a subject chose randomly for each trial, they would get 50% of them correct.\n\nRunning a one-sample t-test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(acc_mean, mu = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  acc_mean\nt = 13.788, df = 9, p-value = 2.34e-07\nalternative hypothesis: true mean is not equal to 0.5\n95 percent confidence interval:\n 0.6962988 0.7733565\nsample estimates:\nmean of x \n0.7348277 \n```\n\n\n:::\n:::\n\n\n**We can see that the accuracy is significantly different to chance level across the participants.**\n\nPsychologists are often interested with understanding the biological and sociological influences on task performance. \nA simple way of testing this is by doing a simple correlation between performance and these factors. \n\nLet's load in some descriptive data which has the 'IQ' and 'Age' for the subjects, and add a column containing their accuracy:\n\n::: {.cell}\n\n```{.r .cell-code}\nload('../_data/RL_descriptive.RData')\ndescriptive$acc = acc_mean\ndf = descriptive\nhead(descriptive)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  subjID        IQ      Age       acc\n1      1 123.98691 31.07218 0.8076923\n2      2  87.63187 30.13800 0.7125000\n3      3  89.39930 23.44219 0.6875000\n4      4  84.34607 27.44848 0.6493506\n5      5 134.72208 23.30624 0.7750000\n6      6  84.60797 25.67858 0.7250000\n```\n\n\n:::\n:::\n\n\nNow let'e see if there is a correlation between 'IQ' or 'Age' with accuracy:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(df$IQ, df$acc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df$IQ and df$acc\nt = 4.8347, df = 8, p-value = 0.001297\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5114810 0.9671586\nsample estimates:\n      cor \n0.8631401 \n```\n\n\n:::\n\n```{.r .cell-code}\ncor.test(df$Age, df$acc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df$Age and df$acc\nt = 0.3857, df = 8, p-value = 0.7098\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5404909  0.7047848\nsample estimates:\n      cor \n0.1351166 \n```\n\n\n:::\n:::\n\n\nFrom the results, we can see that there **is a significantly positive correlation between IQ and accuracy (R = 0.86), whereas there is no such relationship with age**.\n\nThis is more easily visualized by creating a graph using `ggplot2()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create IQ correlation plot\np1 <- ggplot(df, aes(x = IQ, y = acc)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"blue\") +\n  theme_bw() +\n  labs(\n    x = \"IQ Score\",\n    y = \"Accuracy\",\n    title = \"IQ vs. Accuracy\"\n  ) +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(size = 16, hjust = 0.5)\n  )\n\n# Create Age correlation plot\np2 <- ggplot(df, aes(x = Age, y = acc)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"blue\") +\n  theme_bw() +\n  labs(\n    x = \"Age\",\n    y = \"\",\n    title = \"Age vs. Accuracy\"\n  ) +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(size = 16, hjust = 0.5)\n  )\n\n# Combine plots side by side\np1 + p2\n```\n\n::: {.cell-output-display}\n![](working_with_data_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\nBeyond running a simple correlation between two variables, we can develop a model describing their relationship.\nA commonly used model is a **linear model** which assumes that one variable (the outcome or dependent variable) can be predicted by another variable (the predictor or independent variable) using a straight line. \n\nThe line is described by two parameters: **the intercept** (where the line crosses the y-axis) and **the slope** (how much y changes for each unit change in x). This model allows us to make predictions about one variable based on values of the other, and quantifies the strength and direction of their relationship.\n\nA linear regression model is described mathematically by the following function:\n\n$$y = \\beta_0 + \\beta_1x + \\epsilon$$\nWhere:\n\n- $y$ is the dependent variable\n- $β_0$ (beta_0) is the intercept\n- $β_1$ (beta_1) is the slope\n- $x$ is the independent variable\n- $ε$ (epsilon) represents the error term\n\nIn `R` we can run a simple linear regression using the `lm` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 = lm(acc ~ IQ, data = df)\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = acc ~ IQ, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.047305 -0.016277  0.007562  0.022577  0.027731 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.499292   0.049565  10.073 8.04e-06 ***\nIQ          0.002340   0.000484   4.835   0.0013 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02885 on 8 degrees of freedom\nMultiple R-squared:  0.745,\tAdjusted R-squared:  0.7131 \nF-statistic: 23.37 on 1 and 8 DF,  p-value: 0.001297\n```\n\n\n:::\n:::\n\n\nLet's break down the key findings:\n\n1. The relationship is significantly positive, **meaning higher IQ scores are associated with better accuracy**. For each point increase in IQ, accuracy increases by about 0.0023 (this is our slope, β₁ = 0.002340).\n\n2. The model explains about 74.5% of the variance in accuracy scores (R² = 0.745), which indicates this is quite a strong relationship.\n3. The relationship is statistically significant (p = 0.0013), well below the conventional 0.05 threshold, suggesting this isn't just due to chance.\n\nAgain, we can plot this using `ggplot2()`:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = IQ, y = acc)) +\n  geom_point(size = 3) +  # Data points\n  geom_smooth(method = \"lm\", color = \"blue\") +  # Regression line with confidence interval\n  theme_bw() +\n  labs(\n    x = \"IQ Score\",\n    y = \"Accuracy\",\n    title = \"Linear Regression: IQ vs Accuracy\"\n  ) +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(size = 16, hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](working_with_data_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n",
    "supporting": [
      "working_with_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}